\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{tikz}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{tikz-timing}
\usepackage{circuitikz}
\usepackage{float}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usepackage{filecontents}
\usepackage{hyperref}
\usepackage{dirtree}
\usepackage{inconsolata}



\setlength{\headheight}{45.25728pt}
\addtolength{\topmargin}{-33.25728pt}
\addtolength{\topmargin}{-25.03186pt}
\pagestyle{fancy}
\fancyhf{} % Leert Standard Kopf- und Fußzeilen



% Fußlinie aktivieren (Stärke anpassen)
\renewcommand{\footrulewidth}{0.4pt}

% Kopfzeile
\fancyhead[L]{\includegraphics[width=2.5cm]{logo.png}}    % Logo links
\fancyhead[C]{15.10.2025}                               % Datum in der Mitte
\fancyhead[R]{Felix Zauner, Timofey Luzin}                             % Platzhalter für Namen

% Fußzeile
\fancyfoot[L]{5AHETS}                                  % Klasse links
\fancyfoot[C]{ARX}                                   % Mitte Labor
\fancyfoot[R]{Seite \thepage}                          % Seitenzahl rechts

% Define custom colors
\definecolor{vscodeblue}{RGB}{86, 156, 214}          % VSCode blue for keywords
\definecolor{vscodepurple}{RGB}{197, 134, 192}       % VSCode purple for strings
\definecolor{vscodegreen}{RGB}{78, 201, 176}         % VSCode green for comments
\definecolor{vscodeorange}{RGB}{220, 165, 95}        % VSCode orange for numbers
\definecolor{vscodegray}{RGB}{155, 155, 155}         % VSCode gray for line numbers

\begin{document}

\lstset{
    % Font settings (Inconsolata is very similar to VSCode's default)
    basicstyle=\ttfamily\footnotesize,
    % Colors and background
    backgroundcolor=\color{white},
    rulecolor=\color{gray!50},
    % Line numbers
    numbers=left,
    numberstyle=\tiny\color{vscodegray},
    numbersep=8pt,
    % Frame
    frame=single,
    framerule=0.5pt,
    framesep=5pt,
    % Syntax highlighting colors
    commentstyle=\color{vscodegreen},
    keywordstyle=\color{vscodeblue},
    stringstyle=\color{vscodepurple},
    % Layout
    tabsize=4,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    breaklines=true,
    breakatwhitespace=true,
    breakautoindent=true,
    captionpos=b,
    xleftmargin=0pt,
    xrightmargin=0pt,
    framexleftmargin=0pt,  % Remove frame left margin
    framexrightmargin=0pt, % Remove frame right margin
    linewidth=\textwidth  % Use full text width
}

% Titelseite
\begin{titlepage}
    \centering
    \vspace*{2cm}
    % Logo auf Titelseite
    \includegraphics[width=0.5\textwidth]{logo.png}

    \vspace{1.5cm}
    % Titel und Untertitel
    \begin{minipage}{0.9\textwidth}
        \centering
        \Huge\textbf{Automatische Klassifikation von Thorax-Röntgenbildern zur Erkennung von Pneumonie und Tuberkulose}\\
        \vspace{0.5cm}
        
    \end{minipage}
    \Large Projektbericht
    \vspace{1.5cm}

    % Autoren
    \textbf{Gruppe:}\\
    Felix Zauner, Timofey Luzin\\

    \vspace{0.5cm}

    \textbf{Klasse \& Schuljahr:} \\ 5AHETS 2025/26


    \vspace{0.5cm}

    \textbf{Abgabe:} \\ 15.12.2025


\end{titlepage}



\tableofcontents

\newpage
\section{Einleitung}
In diesem Projektbericht wird die Entwicklung eines Modells zur automatischen Klassifikation von Thorax-Röntgenbildern zur Erkennung von Pneumonie und Tuberkulose beschrieben. 
\\
Die KI-basierte Bildanalyse hat in den letzten Jahren erhebliche Fortschritte gemacht und bietet vielversprechende Möglichkeiten zur Unterstützung medizinischer Diagnosen.
Manche Experten sehen in der automatischen Bildanalyse sogar das Potenzial, die Genauigkeit und Effizienz von Diagnosen zu verbessern, insbesondere in ressourcenarmen Umgebungen.
\\
Ziel dieses Projekts ist es, ein Modell zu entwickeln, das in der Lage ist, Thorax-Röntgenbilder zu analysieren und zwischen gesunden Patienten, Patienten mit Pneumonie und Patienten mit Tuberkulose zu unterscheiden.
\\
Der Bericht gliedert sich in mehrere Abschnitte, die den gesamten Entwicklungsprozess abdecken, von der Datensammlung und -aufbereitung über die Modellauswahl und das Training bis hin zur Evaluation des Modells.
Abschließend werden die Herausforderungen und Probleme, die während des Projekts aufgetreten sind, sowie eine Reflexion über die Ergebnisse und mögliche zukünftige Verbesserungen diskutiert.


\newpage

\section{Datensatzbeschreibung}
Der Datensatz stammt beinhaltet insgesamt 25.600 Thorax-Röntgenbilder, die in drei Klassen unterteilt sind: Gesunde Patienten, Patienten mit Pneumonie und Patienten mit Tuberkulose.
Die Bilder sind schon in Trainings-, Validierungs- und Testsets aufgeteilt.\\
In unserer Anwendung verwenden wir \textit{ausschließlich} das \textit{Trainingsset} und das \textit{Testset}.
\\
Insgesamt ist das Datenset 3.31 GB groß.\\
Die Bilder liegen im JPEG-Format vor und haben keine standartisierte Auflösung.
\\
Hier ist eine Übersicht über die Struktur des Datensatzes dargestellt:
\begin{figure}[H]
    \dirtree{%
    .1 chest-xray-dataset.
    .2 versions.
    .3 1.
    .4 \textcolor{green!60!black}{test}.
    .5 \textcolor{green!60!black}{normal}.
    .6 [925 Abbildungen].
    .5 \textcolor{green!60!black}{pneumonia}.
    .6 [580 Abbildungen].
    .5 \textcolor{green!60!black}{tuberculosis}.
    .6 [1064 Abbildungen].
    .4 \textcolor{green!60!black}{train}.
    .5 \textcolor{green!60!black}{normal}.
    .6 [7263 Abbildungen].
    .5 \textcolor{green!60!black}{pneumonia}.
    .6 [4674 Abbildungen].
    .5 \textcolor{green!60!black}{tuberculosis}.
    .6 [8513 Abbildungen].
    .4 val.
    .5 normal.
    .6 [900 Abbildungen].
    .5 pneumonia.
    .6 [570 Abbildungen].
    .5 tuberculosis.
    .6 [1064 Abbildungen].
    .4 data.yaml.
    }
    \caption{Struktur des Datensatzes}
    \label{fig:datensatzstruktur}
\end{figure}

Das Datenset wurde von Kaggle bereitgestellt und ist öffentlich zugänglich unter folgendem Link: \\
https://www.kaggle.com/datasets/muhammadrehan00/chest-xray-dataset
\\\\
Hier eine Auswahl an Beispielbildern aus dem Datensatz in Abbildung 2.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{image copy.png}
    \caption{Beispielabbildung aus dem Datensatz}
    \label{fig:example_image_copy}
\end{figure}
Man kann bereits in diesem Auszug erkennen das die Bilder sehr unterschiedlich im Bezug auf Helligkeit, Kontrast und Bildausschnitt aussehen können, was zusätzlich die Klassifikation erschwert.
\\
Ein weiterer wichtiger Aspekt ist, dass die Unterschiede zwischen den Klassen oft sehr subtil sind und eine genaue Analyse der Bildmerkmale erfordern, um eine zuverlässige Klassifikation zu gewährleisten.
\\ Ebenfalls sind die Klassen im Datensatz im Bezug auf Anzahl der Bilder nicht perfekt ausbalanciert, was bei der Modellentwicklung berücksichtigt werden muss.
\newpage

\section{Datenaufbereitung}
Aufgrund der unterschiedlichen Auflösungen der Bilder im Datensatz war eine sorgfältige Datenaufbereitung erforderlich, um eine konsistente Eingabe für das Modell zu gewährleisten. \\
Die Bilder wurden sowohl auf eine einheitliche Größe von 128x128 Pixel skaliert, als auch in schwarz-weiß umgewandelt, um die Verarbeitung zu erleichtern und die Leistung des Modells zu optimieren. \\
Dies wurde mit der OpenCV-Bibliothek in Python durchgeführt. \\
Das folgende Code-Snippet zeigt die Implementierung der Bildskalierung und der Umwandlung in Graustufen:\\

\begin{lstlisting}[language=Python, caption=Image Resizing und Grayscale Conversion]
import cv2
# Transform and load images
def load_images(folder, label, img_size=(128, 128)):
    X, y = [], []

    for file in os.listdir(folder):
        path = os.path.join(folder, file)
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, img_size)
        X.append(img)
        y.append(label)

    return X, y
\end{lstlisting}

\newpage

\section{Modellauswahl und -training}
\subsection{Modellauswahl}
Zu Beginn des Projektes wurde der bereits im Exposé genannte MLP Classifier implementiert und trainiert. \\ Nach ersten Tests und Evaluierungen wurde jedoch festgestellt, dass die Ergebnisse nicht zufriedenstellend waren. \\
Daraufhin wurde ein zweiter MLP Classifier mit mehr Schichten und optimierten Hyperparametern ausprobiert, um die Leistung zu verbessern. \\
Auf der Suche nach weiteren Verbesserungen wurde auch ein SVM (Support Vector Machine) Classifier mit \& ohne Feature Extraction getestet. \\

Die folgenden Modelle wurden evaluiert:
\begin{itemize}
    \item \textbf{MLP Classifier:} 
\\
Ein mehrschichtiger Perzeptron-Klassifikator (MLP) ist ein Feedforward-Neuronales Netzwerk, das aus mehreren Schichten von Neuronen besteht: einer Eingabeschicht, einer oder mehreren versteckten Schichten und einer Ausgabeschicht. Jede Verbindung zwischen den Neuronen hat ein Gewicht, das während des Trainings angepasst wird. Der MLP verwendet Aktivierungsfunktionen (z.B. ReLU, Sigmoid), um Nichtlinearitäten einzuführen und komplexe Muster in den Daten zu lernen. Das Training erfolgt durch Backpropagation und Optimierungsalgorithmen wie Adam oder SGD, um die Gewichte zu aktualisieren und die Vorhersagegenauigkeit zu maximieren.

   
    \item \textbf{SVM ohne Feature Extraction} \\ 
Ein Support Vector Machine (SVM) ist ein klassischer, margin‑basierter Klassifikator. Grob funktioniert er so: die SVM sucht eine (lineare) Trennfläche im Merkmalsraum, die den Abstand (Margin) zwischen den Klassen maximiert; nur die Trainingspunkte, die die Margin am stärksten bestimmen (Support‑Vectors), beeinflussen das Modell. Für nichtlineare Probleme wird der Kernel‑Trick (z.B. RBF, polynomial) genutzt, der implizit in einen höherdimensionalen Raum abbildet, sodass eine lineare Trennung dort möglich wird. Mit dem Regularisierungsparameter C lässt sich die Toleranz gegenüber Fehlklassifikationen (Soft‑Margin) steuern.
\end{itemize}



\newpage
\subsection{Modelltraining}
Das Training der Modelle erfolgte mit dem vorbereiteten Datensatz. Verschiedene Hyperparameter wurden getestet, um die Leistung zu optimieren.
\begin{itemize}
    \item MLP Classifier: \\ Der Code initialisiert und trainiert einen mehrschichtigen Perzeptron-Klassifikator (MLP) mit einem versteckten Layer. Dazu werden die Bilddaten zunächst abgeflacht, standardisiert und anschließend zum Trainieren des Modells verwendet.

    \begin{lstlisting}[language=Python, caption=MLP Classifier]
# Train MLP Classifier
mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=50, alpha=1e-4, solver='adam', verbose=True, random_state=912)

# Flatten images to (n_samples, n_features) because MLPClassifier expects 2D input
X_train_flat = X_train.reshape(X_train.shape[0], -1)
X_test_flat = X_test.reshape(X_test.shape[0], -1)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_flat)
X_test_scaled = scaler.transform(X_test_flat)

# Fit model
mlp.fit(X_train_scaled, y_train)

    \end{lstlisting}
    
    \vfill
    \item MLP Classifier mit mehr Schichten: \\ Der Code definiert und trainiert einen optimierten MLP-Klassifikator mit zwei versteckten Schichten und erhöhter Modellkapazität. Durch angepasste Trainingsparameter wird eine stabilere und leistungsfähigere Klassifikation auf den skalierten Trainingsdaten erreicht.
    
    \begin{lstlisting}[language=Python, caption=MLP Classifier mit mehr Schichten]
# Optimized MLP with early stopping, higher max_iter and tuned learning rate/batch size
mlp2 = MLPClassifier(hidden_layer_sizes=(100,100), max_iter=100, alpha=1e-4, solver='adam', verbose=True, random_state=912)

# Fit model
mlp2.fit(X_train_scaled, y_train)
    \end{lstlisting}

    \item SVC ohne Feature Extraction \\ Der Code initialisiert einen Support Vector Classifier mit RBF-Kernel und balancierten Klassengewichten. Das Modell wird anschließend mit den skalierten Trainingsdaten trainiert, um eine nichtlineare Klassifikationsgrenze zu erlernen.
    
    \begin{lstlisting}[language=Python, caption=SVC ohne Feature Extraction]
from sklearn.svm import SVC

svc = SVC(
    kernel="rbf",
    C=10,
    gamma="scale",
    class_weight="balanced"
)

svc.fit(X_train_scaled, y_train)
    \end{lstlisting}
    
    \item SVC mit PCA Feature Extraction: \\ Der Code extrahiert HOG-Features aus den Bildern, um relevante Merkmale für die Klassifikation zu gewinnen. Diese Features werden anschließend für das Training eines Support Vector Classifiers verwendet, um die Leistung des Modells zu verbessern.
    
    \begin{lstlisting}[language=Python, caption=SVC mit PCA Feature Extraction]
from skimage.feature import hog

def extract_hog(images):
    features = []
    for img in images:
        hog_feat = hog(
            img,
            orientations=9,
            pixels_per_cell=(8, 8),
            cells_per_block=(2, 2),
            block_norm='L2-Hys'
        )
        features.append(hog_feat)
    return np.array(features)
    \end{lstlisting}
\end{itemize}

\newpage
\subsection{Code-Dokumentation}
Hier sind die während der Vorvearbeitung und dem Training verwendeten Code-Snippets dokumentiert:
\begin{lstlisting}[language=Python, caption=Hauptlibraries]
# Libraries importieren
import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report,
                            confusion_matrix
from sklearn.preprocessing import StandardScaler
import kagglehub
\end{lstlisting}

\begin{lstlisting}[language=Python, caption=Herunterladen des Datensatzes und Pfadzuweisung]
# Download latest version of dataset from Kaggle
path = kagglehub.dataset_download("muhammadrehan00
                            /chest-xray-dataset")

print("Path to dataset files:", path)

# Print the paths to the train and test directories
train_dir = os.path.join(path, "chest_xray", "train")
test_dir = os.path.join(path, "chest_xray", "test")
print("Train directory:", train_dir)
print("Test directory:", test_dir)
\end{lstlisting}
\vfill

\begin{lstlisting}[language=Python, caption=Einteilung der Bilder in Arrays und Labels zur weiteren Verarbeitung durch das entwickelte Modell]
# Prepare training data
X_train, y_train = [], []

# Train
normal_X, normal_y = load_images(os.path.join(path, "train/NORMAL"), "Normal")
pneu_X, pneu_y     = load_images(os.path.join(path, "train/PNEUMONIA"), "Pneumonia")
tub_X, tub_y       = load_images(os.path.join(path, "train/TUBERCULOSIS"), "Tuberculosis")

X_train.extend(normal_X + pneu_X + tub_X)
y_train.extend(normal_y + pneu_y + tub_y)

X_train = np.array(X_train)
y_train = np.array(y_train)

# Prepare testing data
X_test, y_test = [], []

# Test
normal_X, normal_y = load_images(os.path.join(path, "test/NORMAL"), "Normal")
pneu_X, pneu_y     = load_images(os.path.join(path, "test/PNEUMONIA"), "Pneumonia")
tub_X, tub_y       = load_images(os.path.join(path, "test/TUBERCULOSIS"), "Tuberculosis")

X_test.extend(normal_X + pneu_X + tub_X)
y_test.extend(normal_y + pneu_y + tub_y)

X_test = np.array(X_test)
y_test = np.array(y_test)
\end{lstlisting}

\newpage
\subsection{Probleme und Herausforderungen}
Die Ergebnisse sowohl bei MLP Classifier als auch bei SVM waren in unserem Fall unzureichend, mit einem F1 Score von nur etwa 0,7. Dies könnte auf verschiedene Faktoren zurückzuführen sein, darunter die Komplexität der Bilder, die begrenzte Größe des Datensatzes oder die Wahl der Modelle und Hyperparameter. \\
Hingegen wäre die Verwendung eines Convolutional Neural Networks (CNN) eine bessere Wahl gewesen, da CNNs speziell für die Verarbeitung von Bilddaten entwickelt wurden.
Ein CNN ist eine spezialisierte neuronale Netzwerkarchitektur, die mehrere Schichten umfasst:
\begin{itemize}
    \item \textbf{Convolutional Layer:} Diese Schichten wenden Filter (Kernel) auf die Eingabebilder an und extrahieren automatisch räumliche Merkmale wie Kanten, Texturen und Muster. Dies geschieht durch Faltungsoperationen, die lokale Bildbereiche analysieren.
    \item \textbf{Pooling Layer:} Diese Schichten reduzieren die räumliche Dimension der Feature Maps, um Rechenzeit zu sparen und die Modellrobustheit zu verbessern. Max Pooling wählt den maximalen Wert aus einem Fenster, während Average Pooling den Durchschnittswert berechnet.
    \item \textbf{Fully Connected Layer:} Nach mehreren Convolutional und Pooling Schichten folgen vollständig verbundene Schichten, die die extrahierten Merkmale für die Klassifikation nutzen.
\end{itemize}
Der Vorteil von CNNs liegt darin, dass sie Translationsinvarianz aufweisen (ein Merkmal wird erkannt, unabhängig davon, wo es im Bild auftritt) und hierarchische Merkmalsdarstellungen aufbauen. Dies macht sie ideal für medizinische Bildanalyse, wo subtile diagnostische Unterschiede erkannt werden müssen. Die schlechten Ergebnisse unserer bisherigen Modelle deuten darauf hin, dass MLP und SVM nicht in der Lage sind, die komplexen räumlichen Muster in Röntgenbildern ausreichend zu erfassen.
\newpage

\section{Evaluation des Modells}
Die Evaluation der Modelle erfolgte anhand verschiedener Metriken, darunter Genauigkeit, Präzision, Recall und F1-Score. \\
Außerdem wurden für die beiden MLP Classifier ROC Curves erstellt, um die Leistung der Modelle visuell darzustellen.
Hier sind die Ergebnisse der Evaluierung für die verschiedenen Modelle mit verschiedenen Metriken dargestellt:
\begin{itemize}
    \item \textbf{MLP Classifier} mit \texttt{hidden\_layer\_sizes=(128,128,64), max\_iter=300}  \\
    \\Confusion Matrix:
    \[
\begin{bmatrix}
680 & 139 & 106 \\
66 & 507 & 7 \\
366 & 3 & 695
\end{bmatrix}
\]



Classification Report:

\begin{table}[H]
    \centering
 
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\
        \hline
        Normal & 0.61 & 0.74 & 0.67 & 925 \\
        Pneumonia & 0.78 & 0.87 & 0.83 & 580 \\
        Tuberculosis & 0.86 & 0.65 & 0.74 & 1064 \\
        \hline
        \textbf{Accuracy} &&&0.73 & 2569 \\
        \textbf{Macro Avg} & 0.75 & 0.75 & 0.75 & 2569 \\
        \textbf{Weighted Avg} & 0.75 & 0.73 & 0.73 & 2569 \\
        \hline
    \end{tabular}
    \label{tab:classification_report_mlp1}
\end{table}


\item \textbf{MLP Classifier} mit \texttt{hidden\_layer\_sizes=(10), max\_iter=50}  \\
\\Confusion Matrix:
    \[
\begin{bmatrix}
692 & 120 & 113 \\
140 & 428 & 12 \\
384 & 6 & 674
\end{bmatrix}
\]

Classification Report:

\begin{table}[H]
    \centering
 
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\
        \hline
        Normal & 0.57 & 0.75 & 0.65 & 925 \\
        Pneumonia & 0.77 & 0.74 & 0.75 & 580 \\
        Tuberculosis & 0.84 & 0.63 & 0.72 & 1064 \\
        \hline
        \textbf{Accuracy} & && 0.70 & 2569 \\
        \textbf{Macro Avg} & 0.75 & 0.75 & 0.75 & 2569 \\
        \textbf{Weighted Avg} & 0.75 & 0.73 & 0.73 & 2569 \\
        \hline
    \end{tabular}
    \label{tab:classification_report_mlp2}
\end{table}


\item \textbf{SVM} mit \texttt{kernel="rbf", C=10} ohne     Feature Extraction \\
\\Confusion Matrix:
    \[
\begin{bmatrix}
582 & 164 & 179 \\
109 & 466 & 5 \\
405 & 1 & 658
\end{bmatrix}
\]

Classification Report:

\begin{table}[H]
    \centering
 
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\
        \hline
        Normal & 0.53 & 0.63 & 0.58 & 925 \\
        Pneumonia & 0.74 & 0.80 & 0.77 & 580 \\
        Tuberculosis & 0.78 & 0.62 & 0.69 & 1064 \\
        \hline
        \textbf{Accuracy} & &&0.66 & 2569 \\
        \textbf{Macro Avg} & 0.68 & 0.68 & 0.68 & 2569 \\
        \textbf{Weighted Avg} & 0.68 & 0.66 & 0.67 & 2569 \\
        \hline
    \end{tabular}
    \label{tab:classification_report_svm1}
\end{table}

\item \textbf{SVM} mit \texttt{kernel="rbf", C=10} mit Feature Extraction \\
\\Confusion Matrix:
    \[
\begin{bmatrix}
372 & 164 & 389 \\
111 & 469 & 0 \\
404 & 1 & 659
\end{bmatrix}
\]

Classification Report:

\begin{table}[H]
    \centering
 
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\
        \hline
        Normal & 0.42 & 0.40 & 0.41 & 925 \\
        Pneumonia & 0.74 & 0.81 & 0.77 & 580 \\
        Tuberculosis & 0.63 & 0.62 & 0.62 & 1064 \\
        \hline
        \textbf{Accuracy} & & & 0.58 & 2569 \\
        \textbf{Macro Avg} & 0.60 & 0.61 & 0.60 & 2569 \\
        \textbf{Weighted Avg} & 0.58 & 0.58 & 0.58 & 2569 \\
        \hline
    \end{tabular}
    \label{tab:classification_report_svm2}
\end{table}

\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.2\textwidth]{image.png}
    \caption{ROC Curves der beiden MLP Classifier}
    \label{fig:example_image}
\end{figure}
Die ROC Curves in Abbildung 1 zeigen die Leistung der beiden MLP Classifier. 
Eine ROC-Kurve (Receiver Operating Characteristic Curve) ist ein grafisches Werkzeug zur Bewertung der Leistung eines Klassifikationsmodells. Sie stellt die Beziehung zwischen der True Positive Rate (TPR) und der False Positive Rate (FPR) bei verschiedenen Schwellenwerten dar.
\begin{itemize}
    \item \textbf{Diagonal:} Eine ROC-Kurve entlang der Diagonalen (45°-Linie) zeigt, dass das Modell keine bessere Leistung als zufälliges Raten erbringt.
    \item \textbf{Oberhalb der Diagonalen:} Je weiter die Kurve von der Diagonalen entfernt ist, desto besser ist die Trennleistung des Modells.
    \item \textbf{AUC (Area Under the Curve):} Die Fläche unter der ROC-Kurve quantifiziert die Gesamtleistung des Modells. Ein AUC-Wert von 1 bedeutet perfekte Klassifikation, während ein Wert von 0,5 auf Zufallsraten hinweist.
    
\end{itemize}


\newpage

\section{Probleme und Herausforderungen im gesamten Projekt}
\subsection{Technische Herausforderungen}
Während des Projekts traten im Grunde keine technischen Probleme auf. Die Implementierung und das Training der Modelle verliefen größtenteils reibungslos, dank der Verwendung etablierter Bibliotheken wie Scikit-Learn und OpenCV.\\
Auch im Bezug auf die Hardware gab es keine nennenswerten Einschränkungen, da die Modelle mit Wartezeiten von bis zu 20 Minuten auf einem handelsüblichen Laptop trainiert werden konnten, was für uns akzeptabel war.\\
\subsection{Modellierungsprobleme}

Während des Modellierungsprozesses traten mehrere Herausforderungen auf, die die Leistung der Modelle beeinträchtigten:

\begin{itemize}
    \item \textbf{Overfitting:} 
    Insbesondere bei den MLP-Modellen wurde festgestellt, dass sie auf den Trainingsdaten sehr gut abschnitten, jedoch auf den Testdaten eine deutlich schlechtere Leistung zeigten. Dies deutet auf Overfitting hin. 

    \item \textbf{Unbalancierte Daten:}
    Der Datensatz war nicht perfekt ausbalanciert, da die Anzahl der Bilder in den Klassen "Normal", "Pneumonia" und "Tuberculosis" unterschiedlich war. 
    \begin{itemize}
        \item Verwendung des Parameters \texttt{class\_weight="balanced"} in den SVM-Modellen, um die Klassenungleichheit auszugleichen.
        
        \item Evaluation der Modelle mit Metriken wie F1-Score, die für unbalancierte Daten besser geeignet sind.
    \end{itemize}

    \item \textbf{Feature Extraction:}
    Der Versuch, HOG-Features für die SVM-Modelle zu extrahieren, führte nicht zu einer signifikanten Leistungsverbesserung sondern zu einer Verschlechterung. Möglicherweise waren die extrahierten Features nicht repräsentativ für die Klassifikationsaufgabe. Was im Bezug auf die Diagnosemerkmale und der Arbeitsweise von SVMs durchaus Sinn ergibt.
\end{itemize}
Trotz dieser Maßnahmen blieb die Leistung der Modelle begrenzt. Dies deutet darauf hin, dass ein Wechsel zu einem CNN-Modell, das speziell für Bilddaten entwickelt wurde, eine vielversprechende nächste Iteration des Projekts darstellen könnte.


\section{Schlussfolgerung und Reflexion}
Trotz der Implementierung verschiedener Modelle, darunter MLP Classifier und SVM, konnten die gewünschten Leistungsziele nicht erreicht werden. \\
Die Herausforderungen, die während des Projekts auftraten sindkomplexe Bildmerkmale zu erfassen, deuten darauf hin, dass eine andere Modellarchitektur erforderlich ist. \\
Zukünftige Arbeiten sollten sich auf die Implementierung von Convolutional Neural Networks (CNNs) konzentrieren, die speziell für die Verarbeitung von Bilddaten entwickelt wurden und in der Regel bessere Ergebnisse bei der Bildklassifikation erzielen. \\
\\
Trotzalledem konnte aus den Evaluationsergebnissen wertvolle Erkenntnisse gewonnen werden.
So zeigte sich beispielsweise, dass die MLP Classifier im Vergleich zu dem Feature Extraction SVM-Modell wesentlich weniger oft Tuberkoluse als Normal klassifizierten, im Bezug auf die Arbeitsweise von SVMs mit Feature Extraction und der Diagnosemerkmale von Röntgenbildern die sich wie folgt darstellen: 
\begin{itemize}
    \item Tuberkulose kann durch charakteristische Muster wie Kavernen und Konsolidierungen (löchrige Optik) im Lungengewebe erkannt werden.
    \item Pneumonie kann durch flächige Verschattungen und Infiltrate in den Lungenfeldern identifiziert werden.
\end{itemize}
kann so die Erkenntnis gewonnen werden, dass sich SMVs eher an markanten Strukturen orientieren. \\ 
Dadurch wurde wurden die für die Tuberkulose nötigen feinen Unterschiede in den Röntgenbildern nicht erfasst und die Modelle konnten die Klassen nicht ausreichend unterscheiden. \\\\
In der ROC Curve der beiden MLP Classifier ist zu erkennen, dass beide Modelle sehr ähnliche Leistungen erbringen, obwohl das zweite Modell mit nur einer versteckten Schicht und weniger Neuronen deutlich einfacher aufgebaut ist. \\
Dies deutet darauf hin, dass eine weitere Erhöhung der Modellkomplexität nicht zwangsläufig zu einer besseren Leistung führt. \\
Auch kann man erkennen, dass die Fläche unter der Kurve (AUC) welche die Trennschärfe zwischen fälschlicherweise richtig zugeordneten und richtig richtig zugeordneten Klassen quantifiziert bei Pneumonie am höchsten ist, was auf eine bessere Klassifikationsleistung für diese Klasse hinweist. \\\\
Insgesamt bietet dieses Projekt jedoch wertvolle Einblicke in die Herausforderungen der Bildklassifikation im medizinischen Bereich und zeigt deutlich die Gründe für die Wahl von CNNs für den Einsatz in echten Anwendungen auf.


\newpage

\section{Quellen und Literaturverzeichnis}
\begin{itemize}
    \item Scikit-Learn Dokumentation: \url{https://scikit-learn.org/stable/index.html}
    
    \item Kaggle Datensatz: \url{https://www.kaggle.com/datasets/muhammadrehan00/chest-xray-dataset}
    \item Artikel zu MLP Classifier: \url{https://en.wikipedia.org/wiki/Multilayer_perceptron}
    \item Artikel zu SVM: \url{https://en.wikipedia.org/wiki/Support_vector_machine}
\end{itemize}

\newpage

\section{Anhang}

\end{document}